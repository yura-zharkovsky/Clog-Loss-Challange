{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clog Loss: Advance Alzheimerâ€™s Research with Stall Catchers\n",
    "\n",
    "https://www.drivendata.org/competitions/65/clog-loss-alzheimers-research/page/217/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from IPython.lib.display import YouTubeVideo\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed,Dropout, Activation, Flatten,Conv2D, MaxPooling2D,LSTM,Bidirectional\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "from clog_utils import *\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/user/percepto/datasets/ClogLoss'\n",
    "\n",
    "CONSECUTIVE_FRAMES = 10\n",
    "IMG_H, IMG_W, IMG_C = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv(f'{DATASET_PATH}/train_labels.csv')\n",
    "train_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stalled_df = train_labels_df[train_labels_df['stalled'] > 0]\n",
    "train_stalled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df = pd.read_csv(f'{DATASET_PATH}/train_metadata.csv')\n",
    "train_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_df = pd.read_csv(f'{DATASET_PATH}/test_metadata.csv')\n",
    "test_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nano Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {DATASET_PATH}/nano | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nano_df = train_metadata_df[train_metadata_df['nano'] == True]\n",
    "nano_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Micro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {DATASET_PATH}/micro | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_df = train_metadata_df[train_metadata_df['micro'] == True]\n",
    "micro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate that Nano dataset is included inside Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(nano_df['filename'].isin(micro_df['filename']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(x):\n",
    "    return 1. if x > 0.75 else 0\n",
    "\n",
    "get_labels = np.vectorize(get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, folder = nano_df, 'nano'\n",
    "#df, folder = micro_df, 'micro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_paths = DATASET_PATH+'/train/'+train_metadata_df['filename'].values\n",
    "#train_metadata_y = get_labels(train_metadata_df['crowd_score'].values)\n",
    "\n",
    "test_metadata_paths = DATASET_PATH+'/test/'+test_metadata_df['filename'].values\n",
    "\n",
    "train_paths = DATASET_PATH+'/'+folder+'/'+train_df['filename'].values\n",
    "train_y = get_labels(train_df['crowd_score'].values)\n",
    "\n",
    "val_paths = DATASET_PATH+'/'+folder+'/'+val_df['filename'].values\n",
    "val_y = get_labels(val_df['crowd_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Metadata: {len(train_metadata_paths)}')\n",
    "print(f'Test: {len(test_metadata_paths)}')\n",
    "print(f'Trainig: train {len(train_paths)}, validation {len(val_paths)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yutube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('-2aW6m60mYg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('c6TtoQhMrbA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('_uJ_dcy-OXQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('9RFnguYmd_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stalled and Flowing Clips Pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalled_df = df[df['crowd_score'] >=0.5]\n",
    "stalled_paths = DATASET_PATH+'/'+folder+'/'+stalled_df['filename'].values\n",
    "len(stalled_paths), stalled_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowing_df = df[df['crowd_score'] < 0.5]\n",
    "flowing_paths = DATASET_PATH+'/'+folder+'/'+flowing_df['filename'].values\n",
    "len(flowing_paths), flowing_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Flowing Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_clip(flowing_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Stalled Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_clip(stalled_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Test Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_clip(test_metadata_paths[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Clip as Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = read_clip(stalled_paths[100])\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show some clips frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131)\n",
    "plt.imshow(frames[0])\n",
    "plt.subplot(132)\n",
    "plt.imshow(frames[20])\n",
    "plt.subplot(133)\n",
    "plt.imshow(frames[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show some mask with frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = extract_masks(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_fused(frames[30], masks[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 4\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames(path, y):\n",
    "    frames = tf.numpy_function(read_clip, [path, IMG_H, IMG_H], tf.uint8)   \n",
    "    masks = tf.numpy_function(extract_masks, [frames], tf.uint8)\n",
    "    return (frames, masks), y\n",
    "\n",
    "def preprocess(X, y):\n",
    "    frames, masks = X[0], X[1]\n",
    "    frames = tf.cast(frames, tf.float32)\n",
    "    masks = tf.cast(masks, tf.float32)\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    imgs = frames * masks\n",
    "    imgs = imgs/255\n",
    "    n = tf.shape(imgs)[0]\n",
    "    k = n // CONSECUTIVE_FRAMES\n",
    "    imgs = imgs[:k*CONSECUTIVE_FRAMES]\n",
    "    H, W, C = tf.shape(imgs)[1], tf.shape(imgs)[2], tf.shape(imgs)[3]\n",
    "    imgs = tf.reshape(imgs, (k, CONSECUTIVE_FRAMES, H, W, C))\n",
    "    y = tf.reshape(y, (1,))\n",
    "    y = tf.repeat(y, k)\n",
    "    return imgs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train_paths, train_y)).map(read_frames).cache('/tmp/clog_train')\n",
    "val = tf.data.Dataset.from_tensor_slices((val_paths, val_y)).map(read_frames).cache('/tmp/clog_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for i, ((frames, masks), y) in enumerate(train.take(2)):\n",
    "    print(f'{i}: frames={frames.shape}, masks={masks.shape}, y={y}')\n",
    "    display_fused(frames[30].numpy(), masks[30].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for i, ((frames, masks), y) in enumerate(val.take(2)):\n",
    "    print(f'{i}: frames={frames.shape}, masks={masks.shape}, y={y}')\n",
    "    display_fused(frames[30].numpy(), masks[30].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train.repeat()\n",
    "#train_ds = train_ds.shuffle(10)\n",
    "train_ds = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE, deterministic=False)\n",
    "train_ds = train_ds.unbatch()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = val.map(preprocess, num_parallel_calls=AUTOTUNE, deterministic=False)\n",
    "val_ds = val_ds.unbatch()\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X, y) in enumerate(train_ds.take(1)):\n",
    "    print(f'{i}: X={X.shape}, y={y.shape}, label={y.numpy()}')\n",
    "    plt.figure(); plt.imshow(X[0,0]); plt.show\n",
    "    plt.figure(); plt.imshow(X[0,-1]); plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X,y) in enumerate(val_ds.take(1)):\n",
    "    print(f'{i}: X={X.shape}, y={y.shape}, label={y.numpy()}')\n",
    "    plt.figure(); plt.imshow(X[0,0]); plt.show\n",
    "    plt.figure(); plt.imshow(X[0,-1]); plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape\n",
    "print(f'Input Shape: {input_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_backbone():\n",
    "    backbone = Sequential()\n",
    "    backbone.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape[2:]))\n",
    "    backbone.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    backbone.add(MaxPooling2D((2, 2)))\n",
    "    backbone.add(Dropout(0.25))\n",
    "    backbone.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    backbone.add(MaxPooling2D((2, 2)))\n",
    "    backbone.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    backbone.add(MaxPooling2D((2, 2)))\n",
    "    backbone.add(Flatten())\n",
    "    return backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(backbone):\n",
    "    model=Sequential()\n",
    "    model.add(TimeDistributed(backbone,input_shape=input_shape[1:]))\n",
    "    model.add(Bidirectional(LSTM(32)))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    backbone = make_backbone()\n",
    "    model = make_model(backbone)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.optimizers.Adam(2*1e-4),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "steps = []\n",
    "for i, X in enumerate(train):\n",
    "    n = (X[0][0].shape[0] // CONSECUTIVE_FRAMES)\n",
    "    steps.append(n)\n",
    "    if i % 50 == 0:\n",
    "        print(i, np.sum(steps))\n",
    "        \n",
    "steps_per_epoch = np.sum(steps)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "steps = []\n",
    "for i, X in enumerate(val):\n",
    "    n = (X[0][0].shape[0] // CONSECUTIVE_FRAMES)\n",
    "    steps.append(n)\n",
    "    if i % 50 == 0:\n",
    "        print(i, np.sum(steps))\n",
    "        \n",
    "validation_steps = np.sum(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 5698 // BATCH_SIZE\n",
    "validation_steps = 2448 // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'steps_per_epoch {steps_per_epoch}')\n",
    "print(f'validation_steps {validation_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/cp.ckpt', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n",
    "\n",
    "model.fit(train_ds, \n",
    "          initial_epoch=0,\n",
    "          epochs=60, \n",
    "          steps_per_epoch=steps_per_epoch, \n",
    "          validation_data=val_ds, \n",
    "          validation_steps=validation_steps,\n",
    "          callbacks=[modelCheckpoint], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_models/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i, (path, y) in enumerate(zip(val_paths, val_y)):\n",
    "    frames = read_clip(path, IMG_H, IMG_W)\n",
    "    masks = extract_masks(frames)\n",
    "    X, _ = preprocess([frames, masks], y)\n",
    "    p = np.argmax(model(X).numpy(), axis=-1)  \n",
    "    p = (np.sum(p)/len(p) > 0.5).astype(np.int32)\n",
    "    y_pred.append(p)\n",
    "    print(f'{i}[{len(val_y)}]: path={path}, y={y}, p={p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = val_y[:len(pred_y)]\n",
    "y_pred = np.array(pred_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred = y_true # should be 1\n",
    "#y_pred = 1-y_true # should be -1\n",
    "y_pred = np.random.randint(0, 2, y_true.shape) #  should be around 0\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matthews_corrcoef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
